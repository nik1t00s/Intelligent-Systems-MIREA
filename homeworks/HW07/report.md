# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4: 01, 02, 03

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 8 признаков (не считая sample_id)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков, присутствуют выбросы, неравномерная плотность распределения признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 3 признака (не считая sample_id)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: шкалы различаются, небольшие шумовые признаки, неравномерная плотность распределения признаков

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 4 признака (не считая sample_id)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные масштабы, шумовые признаки, неравномерная плотность распределения признаков

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: применен `StandardScaler` к числовым признакам.
- Поиск гиперпараметров:
  - KMeans: `k` в диапазоне 2…20, зафиксирован `random_state` и `n_init=10`. Выбор лучшего k по методу локтя и коэффициенту силуэта.
  - DBSCAN: подбор `eps` с шагом (20 точек между 0.1 и 5.0), `min_samples=5`. Лучший eps выбирался по максимальному silhouette без шума.
- Метрики: рассчитывались `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`. Для DBSCAN метрики считались только на non-noise точках, шум (-1) учитывался отдельно, выводилась доля шума.
- Визуализация: PCA(2D) scatter с раскраской по лучшим кластерам. Опционально t-SNE не использовался.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- Датасет 01:
  - KMeans: поиск `k=2…20`, `random_state=666`, `n_init=10`
  - DBSCAN: поиск `eps=0.1…0.6`, `min_samples=5`, оценка доли шума
- Датасет 02:
  - KMeans: поиск `k=2…20`, `random_state=666`, `n_init=10`
  - DBSCAN: поиск `eps=0.1…0.6`, `min_samples=5`, оценка доли шума
- Датасет 03:
  - KMeans: поиск `k=2…20`, `random_state=666`, `n_init=10`
  - DBSCAN: поиск `eps=0.1…0.6`, `min_samples=5`, оценка доли шума

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN, eps=1.6473684210526318, min_samples=5
- Метрики:
  - KMeans: silhouette=0.383, DB=1.16, CH=9427
  - DBSCAN: silhouette=0.522, DB=0.685, CH=11787
- Доля шума DBSCAN: 0%
- Комментарий: DBSCAN выявил плотные кластеры, не чувствителен к разным шкалам, KMeans хорошо работает, но немного хуже по DB и CH. Пропусков нет, шкалы разные, поэтому DBSCAN оказался более подходящим.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans, k=2
- Метрики:
  - KMeans: silhouette=0.307, DB=1.323, CH=3573
  - DBSCAN: silhouette=0.259, DB=0.615, CH=25.675
- Доля шума DBSCAN: 6.7%
- Комментарий: DBSCAN обнаружил шум, но метрики существенно хуже из-за разреженности данных. KMeans выбрана как более стабильный вариант.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, k=3
- Метрики:
  - KMeans: silhouette=0.316, DB=1.158, CH=6957
  - DBSCAN: silhouette=0.058, DB=0.957, CH=1572
- Доля шума DBSCAN: 5.3%
- Комментарий: DBSCAN почти не формирует плотные кластеры, метрики низкие. KMeans лучше захватывает структуру, несмотря на шумовой признак.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans хорошо работает на плотных кластерах, но чувствителен к выбросам и масштабам.
- DBSCAN хорошо справляется с плотными кластерами и выявлением шума, но на разреженных датасетах метрики могут быть низкими.
- Масштабирование критично для всех алгоритмов; выбросы и плотность сильно влияют на результаты. Пропуски отсутствуют, категориальные признаки не использовались.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: Датасет 01, 5 запусков KMeans с разными `random_state` (0,5,10,15,20), вычисление ARI между разбиениями.
- Результат: ARI=1.0 для всех пар запусков
- Вывод: разбиения устойчивы к инициализации, метод стабилен.

### 5.3 Интерпретация кластеров

 Для каждого датасета смотрелись распределения признаков внутри кластеров.
- Датасет 01: f16 сильнее всего влиял, затем f01; остальные признаки менее значимы.
- Датасет 02: шумовой признак заметно повлиял на DBSCAN, KMeans выявил логичные кластеры.
- Датасет 03: шумовой признак f_noise почти не повлиял на KMeans, DBSCAN мало информативен.
- Вывод: кластеры отражают основные закономерности данных; влияние шумовых признаков ограничено.

## 6. Conclusion

- Применен KMeans и DBSCAN ко всем трем датасетам.
- Масштабирование и обработка пропусков обязательны для корректной кластеризации.
- DBSCAN полезен для выявления плотных кластеров и шума, но чувствителен к разреженности данных.
- KMeans стабилен, хорошо работает на всех датасетах с различной плотностью.
- Метрики (silhouette, DB, CH) помогают объективно сравнивать методы.
- Визуализация PCA помогает интерпретировать кластеры.
- Проверка устойчивости показала стабильность KMeans на Датасете 01.
- Правильный протокол препроцессинга, поиска параметров и сохранения артефактов критичен для воспроизводимости эксперимента.